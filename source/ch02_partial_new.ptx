<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="ch-summarizing-data" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Summarizing data</title>

  <introduction>
    <p>
      This chapter focuses on the mechanics and construction of summary statistics and graphs.
      We use statistical software for generating the summaries and graphs presented in this chapter and book.
      However, since this might be your first exposure to these concepts, we take our time in this chapter to detail
      how to create them.
      Mastery of the content presented in this chapter will be crucial for understanding the methods and
      techniques introduced in rest of the book.
    </p>
  </introduction>

  <!-- Section 2.1: Examining numerical data -->
  <section xml:id="sec-numerical-data">
    <title>Examining numerical data</title>

    <introduction>
      <p>
        In this section we will explore techniques for summarizing numerical variables.
        For example, consider the <c>loan_amount</c> variable from the <c>loan50</c> data set,
        which represents the loan size for all 50 loans in the data set.
        This variable is numerical since we can sensibly discuss the numerical difference of the size of two loans.
        On the other hand, area codes and zip codes are not numerical, but rather they are categorical variables.
      </p>

      <p>
        Throughout this section and the next, we will apply these methods using the <c>loan50</c> and <c>county</c>
        data sets, which were introduced in <xref ref="sec-data-basics"/>.
        If you'd like to review the variables from either data set, see the relevant data description figures.
      </p>
    </introduction>

    <!-- Subsection 2.1.1: Scatterplots for paired data -->
    <subsection xml:id="subsec-scatterplots">
      <title>Scatterplots for paired data</title>

      <p>
        A <term>scatterplot</term> provides a case-by-case view of data for two numerical variables.
        In a previous figure, a scatterplot was used to examine the homeownership rate against the fraction
        of housing units that were part of multi-unit properties (e.g. apartments) in the <c>county</c> data set.
        Another scatterplot is shown in <xref ref="fig-loan50-amt-vs-income"/>, comparing the total income of
        a borrower (<c>total_income</c>) and the amount they borrowed (<c>loan_amount</c>) for the <c>loan50</c> data set.
        In any scatterplot, each point represents a single case.
        Since there are 50 cases in <c>loan50</c>, there are 50 points in <xref ref="fig-loan50-amt-vs-income"/>.
      </p>

      <figure xml:id="fig-loan50-amt-vs-income">
        <caption>A scatterplot of <c>total_income</c> versus <c>loan_amount</c> for the <c>loan50</c> data set</caption>
        <image source="ch_summarizing_data/figures/loan50_amt_vs_interest/loan50_amt_vs_interest.png" width="80%">
          <description>
            A scatterplot is shown with "Total Income" along the horizontal axis (range from $0 to $325,000) and
            "Loan Amount" along the vertical axis (range from $0 to $40,000). The points lie in a range from $2,000
            to $33,000 in loan amount when total income is smaller than $150,000 (representing most of the points).
            The range of loan amounts is higher when total income is greater than $175,000, with the range of
            observations being about $15,000 to $40,000.
          </description>
        </image>
      </figure>

      <p>
        Looking at <xref ref="fig-loan50-amt-vs-income"/>, we see that there are many borrowers with an income
        below $100,000 on the left side of the graph, while there are a handful of borrowers with income above $250,000.
      </p>

      <example xml:id="ex-nonlinear-relationship">
        <title>Nonlinear relationships in scatterplots</title>
        <statement>
          <p>
            <xref ref="fig-median-income-poverty"/> shows a plot of median household income against the poverty
            rate for 3,142 counties. What can be said about the relationship between these variables?
          </p>
        </statement>
        <solution>
          <p>
            The relationship is evidently <term>nonlinear</term>, as highlighted by the dashed line.
            This is different from previous scatterplots we've seen, which show relationships that do not show
            much, if any, curvature in the trend.
          </p>
        </solution>
      </example>

      <figure xml:id="fig-median-income-poverty">
        <caption>A scatterplot of the median household income against the poverty rate for the <c>county</c> data set</caption>
        <image source="ch_summarizing_data/figures/medianHHIncomePoverty/medianHHIncomePoverty.png" width="80%">
          <description>
            A scatterplot of a few thousand points is shown with "Poverty Rate" along the horizontal axis
            (range from 0% to 55%) and "Median Household Income" along the vertical axis (range from $0 to $130,000).
            A curved trend line is overlaid on the points starting higher on the left and decreasing as it moves right,
            but it starts flattening the further right it goes. Below 10% poverty rate, points range from about $40,000
            to $130,000. Between 10% to 20%, the range is lower at about $25,000 to close to $100,000. For 20% to 30%,
            the points range from about $22,000 to just over $60,000. For 30% to 50%, the trend is mostly flat with
            values ranging from about $20,000 to $50,000.
          </description>
        </image>
      </figure>

      <exercise xml:id="ex-scatterplot-usefulness">
        <title>Value of scatterplots</title>
        <statement>
          <p>
            What do scatterplots reveal about the data, and how are they useful?
          </p>
        </statement>
        <solution>
          <p>
            Answers may vary. Scatterplots are helpful in quickly spotting associations relating variables,
            whether those associations come in the form of simple trends or whether those relationships are more complex.
          </p>
        </solution>
      </exercise>

      <exercise xml:id="ex-horseshoe-association">
        <title>Horseshoe-shaped associations</title>
        <statement>
          <p>
            Describe two variables that would have a horseshoe-shaped association in a scatterplot
            (<m>\cap</m> or <m>\frown</m>).
          </p>
        </statement>
        <solution>
          <p>
            Consider the case where your vertical axis represents something "good" and your horizontal axis
            represents something that is only good in moderation. Health and water consumption fit this description:
            we require some water to survive, but consume too much and it becomes toxic and can kill a person.
          </p>
        </solution>
      </exercise>
    </subsection>

    <!-- Subsection 2.1.2: Dot plots and the mean -->
    <subsection xml:id="subsec-dot-plots-mean">
      <title>Dot plots and the mean</title>

      <p>
        Sometimes two variables are one too many: only one variable may be of interest.
        In these cases, a dot plot provides the most basic of displays.
        A <term>dot plot</term> is a one-variable scatterplot; an example using the interest rate of 50 loans
        is shown in <xref ref="fig-loan-int-rate-dot-plot"/>.
        A stacked version of this dot plot is shown in <xref ref="fig-loan-int-rate-dot-plot-stacked"/>.
      </p>

      <figure xml:id="fig-loan-int-rate-dot-plot">
        <caption>A dot plot of <c>interest_rate</c> for the <c>loan50</c> data set</caption>
        <image source="ch_summarizing_data/figures/loan_int_rate_dot_plot/loan_int_rate_dot_plot.png" width="76%">
          <description>
            A dot plot is shown for the variable "Interest Rate". There is a horizontal axis ranging from about 5%
            to a bit over 25%, and then several points are shown horizontally above the axis, scattered over the range.
            There is a higher density of points between 5% to 11%, with a moderate density of points from 12% to about 20%,
            and then a few more observations at about 22%, 25%, and 26%. A red triangle is also shown at approximately 12%.
          </description>
        </image>
      </figure>

      <figure xml:id="fig-loan-int-rate-dot-plot-stacked">
        <caption>A stacked dot plot of <c>interest_rate</c> for the <c>loan50</c> data set</caption>
        <image source="ch_summarizing_data/figures/loan_int_rate_dot_plot/loan_int_rate_dot_plot_stacked.png" width="76%">
          <description>
            A stacked dot plot is shown for the variable "Interest Rate". There is a horizontal axis ranging from about 5%
            to a bit over 25%, and then several stacks of points are shown at values 5%, 6%, 7%, and so on. There are 3 points
            stacked at 5%, 3 points stacked at 6%, 5 at 7%, 4 at 8%, 5 at 9%, 8 at 10%, 5 at 11%, 1 at 11%, 3 at 12%, then
            1 each at 14%, 15%, and 16%, 3 at 17%, 2 at 18%, and then 1 each at 19%, 20%, 21%, 25%, and 26%. A red triangle
            is also shown at approximately 12%. The rates have been rounded to the nearest percent in this plot.
          </description>
        </image>
      </figure>

      <p>
        The <term>mean</term>, often called the <term>average</term>, is a common way to measure the center of a
        <term>distribution</term> of data. To compute the mean interest rate, we add up all the interest rates and
        divide by the number of observations:
        <md>
          <mrow>\bar{x} = \frac{10.90\% + 9.92\% + 26.30\% + \cdots + 6.08\%}{50} = 11.57\%</mrow>
        </md>
        The sample mean is often labeled <m>\bar{x}</m>. The letter <m>x</m> is being used as a generic placeholder
        for the variable of interest, <c>interest_rate</c>, and the bar over the <m>x</m> communicates we're looking
        at the average interest rate, which for these 50 loans was 11.57%. It is useful to think of the mean as the
        balancing point of the distribution, and it's shown as a triangle in <xref ref="fig-loan-int-rate-dot-plot"/>
        and <xref ref="fig-loan-int-rate-dot-plot-stacked"/>.
      </p>

      <assemblage xml:id="def-mean">
        <title>Mean</title>
        <p>
          The sample mean can be computed as the sum of the observed values divided by the number of observations:
          <md>
            <mrow>\bar{x} = \frac{x_1 + x_2 + \cdots + x_n}{n}</mrow>
          </md>
          where <m>x_1</m>, <m>x_2</m>, <m>\dots</m>, <m>x_n</m> represent the <m>n</m> observed values.
        </p>
      </assemblage>

      <exercise xml:id="ex-mean-notation">
        <title>Understanding mean notation</title>
        <statement>
          <p>
            Examine the equation for the mean. What does <m>x_1</m> correspond to? And <m>x_2</m>?
            Can you infer a general meaning to what <m>x_i</m> might represent?
          </p>
        </statement>
        <solution>
          <p>
            <m>x_1</m> corresponds to the interest rate for the first loan in the sample (10.90%),
            <m>x_2</m> to the second loan's interest rate (9.92%), and <m>x_i</m> corresponds to the
            interest rate for the <m>i^{th}</m> loan in the data set. For example, if <m>i = 4</m>,
            then we're examining <m>x_4</m>, which refers to the fourth observation in the data set.
          </p>
        </solution>
      </exercise>

      <exercise xml:id="ex-sample-size-n">
        <title>Sample size</title>
        <statement>
          <p>
            What was <m>n</m> in this sample of loans?
          </p>
        </statement>
        <solution>
          <p>
            The sample size was <m>n = 50</m>.
          </p>
        </solution>
      </exercise>

      <p>
        The <c>loan50</c> data set represents a sample from a larger population of loans made through Lending Club.
        We could compute a mean for this population in the same way as the sample mean.
        However, the population mean has a special label: <m>\mu</m>.
        The symbol <m>\mu</m> is the Greek letter <em>mu</em> and represents the average of all observations in the population.
        Sometimes a subscript, such as <m>_x</m>, is used to represent which variable the population mean refers to,
        e.g. <m>\mu_x</m>. Often times it is too expensive to measure the population mean precisely, so we often
        estimate <m>\mu</m> using the sample mean, <m>\bar{x}</m>.
      </p>

      <example xml:id="ex-estimating-population-mean">
        <title>Estimating a population mean</title>
        <statement>
          <p>
            The average interest rate across all loans in the population can be estimated using the sample data.
            Based on the sample of 50 loans, what would be a reasonable estimate of <m>\mu_x</m>, the mean interest
            rate for all loans in the full data set?
          </p>
        </statement>
        <solution>
          <p>
            The sample mean, 11.57%, provides a rough estimate of <m>\mu_x</m>. While it's not perfect,
            this is our single best guess of the average interest rate of all the loans in the population under study.
            In later chapters, we will develop tools to characterize the accuracy of <term>point estimates</term>
            like the sample mean. As you might have guessed, point estimates based on larger samples tend to be
            more accurate than those based on smaller samples.
          </p>
        </solution>
      </example>

      <example xml:id="ex-mean-for-comparison">
        <title>Using the mean for comparisons</title>
        <statement>
          <p>
            The mean is useful because it allows us to rescale or standardize a metric into something more easily
            interpretable and comparable. Provide 2 examples where the mean is useful for making comparisons.
          </p>
        </statement>
        <solution>
          <p>
            <ol>
              <li>
                <p>
                  We would like to understand if a new drug is more effective at treating asthma attacks than
                  the standard drug. A trial of 1500 adults is set up, where 500 receive the new drug, and 1000
                  receive a standard drug in the control group. The results show 200 asthma attacks in the new
                  drug group and 300 in the standard drug group. Comparing the raw counts of 200 to 300 asthma
                  attacks would make it appear that the new drug is better, but this is an artifact of the
                  imbalanced group sizes. Instead, we should look at the average number of asthma attacks per
                  patient in each group: New drug: <m>200 / 500 = 0.4</m>, Standard drug: <m>300 / 1000 = 0.3</m>.
                  The standard drug has a lower average number of asthma attacks per patient than the average in
                  the treatment group.
                </p>
              </li>
              <li>
                <p>
                  Emilio opened a food truck last year where he sells burritos, and his business has stabilized
                  over the last 3 months. Over that 3 month period, he has made $11,000 while working 625 hours.
                  Emilio's average hourly earnings provides a useful statistic for evaluating whether his venture is,
                  at least from a financial perspective, worth it: <m>\$11000 / 625 \text{ hours} = \$17.60 \text{ per hour}</m>.
                  By knowing his average hourly wage, Emilio now has put his earnings into a standard unit that is
                  easier to compare with many other jobs that he might consider.
                </p>
              </li>
            </ol>
          </p>
        </solution>
      </example>

      <example xml:id="ex-weighted-mean">
        <title>Weighted means</title>
        <statement>
          <p>
            Suppose we want to compute the average income per person in the US. To do so, we might first think
            to take the mean of the per capita incomes across the 3,142 counties in the <c>county</c> data set.
            What would be a better approach?
          </p>
        </statement>
        <solution>
          <p>
            The <c>county</c> data set is special in that each county actually represents many individual people.
            If we were to simply average across the income variable, we would be treating counties with 5,000 and
            5,000,000 residents equally in the calculations. Instead, we should compute the total income for each
            county, add up all the counties' totals, and then divide by the number of people in all the counties.
            If we completed these steps with the <c>county</c> data, we would find that the per capita income for
            the US is $30,861. Had we computed the simple mean of per capita income across counties, the result
            would have been just $26,093! This example used what is called a <term>weighted mean</term>.
            For more information on this topic, check out online supplements regarding weighted means.
          </p>
        </solution>
      </example>
    </subsection>

    <!-- Subsection 2.1.3: Histograms and shape -->
    <subsection xml:id="subsec-histograms-shape">
      <title>Histograms and shape</title>

      <p>
        Dot plots show the exact value for each observation. This is useful for small data sets, but they can
        become hard to read with larger samples. Rather than showing the value of each observation, we prefer
        to think of the value as belonging to a <em>bin</em>. For example, in the <c>loan50</c> data set, we
        created a table of counts for the number of loans with interest rates between 5.0% and 7.5%, then the
        number of loans with rates between 7.5% and 10.0%, and so on. Observations that fall on the boundary
        of a bin (e.g. 10.00%) are allocated to the lower bin. This tabulation is shown in
        <xref ref="table-binned-int-rate"/>. These binned counts are plotted as bars in
        <xref ref="fig-loan50-int-rate-hist"/> into what is called a <term>histogram</term>, which resembles
        a more heavily binned version of the stacked dot plot.
      </p>

      <table xml:id="table-binned-int-rate">
        <title>Counts for the binned <c>interest_rate</c> data</title>
        <tabular>
          <row header="yes" bottom="medium">
            <cell>Interest Rate</cell>
            <cell>5.0%-7.5%</cell>
            <cell>7.5%-10.0%</cell>
            <cell>10.0%-12.5%</cell>
            <cell>12.5%-15.0%</cell>
            <cell><m>\cdots</m></cell>
            <cell>25.0%-27.5%</cell>
          </row>
          <row>
            <cell>Count</cell>
            <cell>11</cell>
            <cell>15</cell>
            <cell>8</cell>
            <cell>4</cell>
            <cell><m>\cdots</m></cell>
            <cell>1</cell>
          </row>
        </tabular>
      </table>

      <figure xml:id="fig-loan50-int-rate-hist">
        <caption>A histogram of <c>interest_rate</c>. This distribution is strongly skewed to the right.</caption>
        <image source="ch_summarizing_data/figures/loan50IntRateHist/loan50IntRateHist.png" width="76%">
          <description>
            A histogram with a horizontal axis of "Interest Rate" and a vertical axis showing the frequency of
            occurrence of different bins of interest rate. The first bin is from 5%-7.5% with a frequency (count)
            of 11 observations, 7.5%-10% has a frequency of 15, 10%-12.5% has 8, 12.5%-15% has 4, 15%-17.5% has 5,
            17.5%-20% has 4, and then the 20%-22.5%, 22.5%-25%, and 25%-27.5% bins each have a frequency of 1.
          </description>
        </image>
      </figure>

      <p>
        Histograms provide a view of the <term>data density</term>. Higher bars represent where the data are
        relatively more common. For instance, there are many more loans with rates between 5% and 10% than loans
        with rates between 20% and 25% in the data set. The bars make it easy to see how the density of the data
        changes relative to the interest rate.
      </p>

      <p>
        Histograms are especially convenient for understanding the shape of the data distribution.
        <xref ref="fig-loan50-int-rate-hist"/> suggests that most loans have rates under 15%, while only a
        handful of loans have rates above 20%. When data trail off to the right in this way and has a longer
        right tail, the shape is said to be <term>right skewed</term>.<fn>Other ways to describe data that are
        right skewed: skewed to the right, skewed to the high end, or skewed to the positive end.</fn>
      </p>

      <p>
        Data sets with the reverse characteristic <mdash/> a long, thinner tail to the left <mdash/> are said
        to be <term>left skewed</term>. We also say that such a distribution has a long left tail. Data sets
        that show roughly equal trailing off in both directions are called <term>symmetric</term>.
      </p>

      <assemblage xml:id="assemblage-long-tails">
        <title>Long tails to identify skew</title>
        <p>
          When data trail off in one direction, the distribution has a <term>long tail</term>. If a distribution
          has a long left tail, it is left skewed. If a distribution has a long right tail, it is right skewed.
        </p>
      </assemblage>

      <exercise xml:id="ex-skew-in-plots">
        <title>Identifying skew</title>
        <statement>
          <p>
            Take a look at the dot plots in earlier figures. Can you see the skew in the data? Is it easier to
            see the skew in this histogram or the dot plots?
          </p>
        </statement>
        <solution>
          <p>
            The skew is visible in all three plots, though the flat dot plot is the least useful. The stacked
            dot plot and histogram are helpful visualizations for identifying skew.
          </p>
        </solution>
      </exercise>

      <exercise xml:id="ex-histogram-vs-dotplot">
        <title>Histogram limitations</title>
        <statement>
          <p>
            Besides the mean (since it was labeled), what can you see in the dot plots that you cannot see in
            the histogram?
          </p>
        </statement>
        <solution>
          <p>
            The interest rates for individual loans.
          </p>
        </solution>
      </exercise>

      <p>
        In addition to looking at whether a distribution is skewed or symmetric, histograms can be used to
        identify modes. A <term>mode</term> is represented by a prominent peak in the distribution. There is
        only one prominent peak in the histogram of <c>loan_amount</c>.
      </p>

      <p>
        A definition of <em>mode</em> sometimes taught in math classes is the value with the most occurrences
        in the data set. However, for many real-world data sets, it is common to have <em>no</em> observations
        with the same value in a data set, making this definition impractical in data analysis.
      </p>

      <p>
        <xref ref="fig-modal-plots"/> shows histograms that have one, two, or three prominent peaks. Such
        distributions are called <term>unimodal</term>, <term>bimodal</term>, and <term>multimodal</term>,
        respectively. Any distribution with more than 2 prominent peaks is called multimodal. Notice that there
        was one prominent peak in the unimodal distribution with a second less prominent peak that was not
        counted since it only differs from its neighboring bins by a few observations.
      </p>

      <figure xml:id="fig-modal-plots">
        <caption>Distributions showing different numbers of modes</caption>
        <image source="ch_summarizing_data/figures/singleBiMultiModalPlots/singleBiMultiModalPlots.png" width="90%">
          <description>
            Three histograms are shown. The first histogram shows bins of width 2 between 0 to 18 (this is along
            the horizontal axis), and the frequencies are 3, 16, 16, 7, 11, 6, 4, 1, and 1. The second histogram,
            representing a different data set, shows bins of width 2 with values ranging from 0 to 20, where the
            bin counts in order are 2, 9, 5, 2, 2, 2, 2, 10, 19, and 9. The third histogram, representing yet
            another data set, shows bins of width 2 with values ranging from 0 to 22, where the bin counts in
            order are 10, 8, 4, 3, 1, 20, 15, 3, 15, 18, and 5.
          </description>
        </image>
      </figure>

      <example xml:id="ex-unimodal-classification">
        <title>Identifying modality</title>
        <statement>
          <p>
            <xref ref="fig-loan50-int-rate-hist"/> reveals only one prominent mode in the interest rate. Is the
            distribution unimodal, bimodal, or multimodal?
          </p>
        </statement>
        <solution>
          <p>
            Unimodal. Remember that <em>uni</em> stands for 1 (think <em>uni</em>cycles). Similarly, <em>bi</em>
            stands for 2 (think <em>bi</em>cycles). We're hoping a <em>multicycle</em> will be invented to
            complete this analogy.
          </p>
        </solution>
      </example>

      <exercise xml:id="ex-height-modes">
        <title>Expected modes in height data</title>
        <statement>
          <p>
            Height measurements of young students and adult teachers at a K-3 elementary school were taken. How
            many modes would you expect in this height data set?
          </p>
        </statement>
        <solution>
          <p>
            There might be two height groups visible in the data set: one of the students and one of the adults.
            That is, the data are probably bimodal.
          </p>
        </solution>
      </exercise>

      <p>
        Looking for modes isn't about finding a clear and correct answer about the number of modes in a
        distribution, which is why <em>prominent</em> is not rigorously defined in this book. The most important
        part of this examination is to better understand your data.
      </p>
    </subsection>

    <!-- Subsection 2.1.4: Variance and standard deviation -->
    <subsection xml:id="subsec-variance-sd">
      <title>Variance and standard deviation</title>

      <p>
        The mean was introduced as a method to describe the center of a data set, and variability in the data
        is also important. Here, we introduce two measures of variability: the variance and the standard
        deviation. Both of these are very useful in data analysis, even though their formulas are a bit tedious
        to calculate by hand. The standard deviation is the easier of the two to comprehend, and it roughly
        describes how far away the typical observation is from the mean.
      </p>

      <p>
        We call the distance of an observation from its mean its <term>deviation</term>. Below are the deviations
        for the 1<m>^{st}</m>, 2<m>^{nd}</m>, 3<m>^{rd}</m>, and 50<m>^{th}</m> observations in the
        <c>interest_rate</c> variable:
        <md>
          <mrow>x_1 - \bar{x} \amp = 10.90 - 11.57 = -0.67</mrow>
          <mrow>x_2 - \bar{x} \amp = 9.92 - 11.57 = -1.65</mrow>
          <mrow>x_3 - \bar{x} \amp = 26.30 - 11.57 = 14.73</mrow>
          <mrow>\amp \vdots</mrow>
          <mrow>x_{50} - \bar{x} \amp = 6.08 - 11.57 = -5.49</mrow>
        </md>
        If we square these deviations and then take an average, the result is equal to the sample
        <term>variance</term>, denoted by <m>s^2</m>:
        <md>
          <mrow>s^2 \amp = \frac{(-0.67)^2 + (-1.65)^2 + (14.73)^2 + \cdots + (-5.49)^2}{50-1}</mrow>
          <mrow>\amp = \frac{0.45 + 2.72 + 216.97 + \cdots + 30.14}{49}</mrow>
          <mrow>\amp = 25.52</mrow>
        </md>
        We divide by <m>n - 1</m>, rather than dividing by <m>n</m>, when computing a sample's variance; there's
        some mathematical nuance here, but the end result is that doing this makes this statistic slightly more
        reliable and useful.
      </p>

      <p>
        Notice that squaring the deviations does two things. First, it makes large values relatively much larger,
        seen by comparing <m>(-0.67)^2</m>, <m>(-1.65)^2</m>, <m>(14.73)^2</m>, and <m>(-5.49)^2</m>. Second, it
        gets rid of any negative signs.
      </p>

      <p>
        The <term>standard deviation</term> is defined as the square root of the variance:
        <md>
          <mrow>s = \sqrt{25.52} = 5.05</mrow>
        </md>
        While often omitted, a subscript of <m>_x</m> may be added to the variance and standard deviation, i.e.
        <m>s_x^2</m> and <m>s_x</m>, if it is useful as a reminder that these are the variance and standard
        deviation of the observations represented by <m>x_1</m>, <m>x_2</m>, ..., <m>x_n</m>.
      </p>

      <assemblage xml:id="def-variance-sd">
        <title>Variance and standard deviation</title>
        <p>
          The variance is the average squared distance from the mean. The standard deviation is the square root
          of the variance. The standard deviation is useful when considering how far the data are distributed
          from the mean.
        </p>
        <p>
          The standard deviation represents the typical deviation of observations from the mean. Usually about
          70% of the data will be within one standard deviation of the mean and about 95% will be within two
          standard deviations. However, these percentages are not strict rules.
        </p>
      </assemblage>

      <p>
        Like the mean, the population values for variance and standard deviation have special symbols: <m>\sigma^2</m>
        for the variance and <m>\sigma</m> for the standard deviation. The symbol <m>\sigma</m> is the Greek
        letter <em>sigma</em>.
      </p>

      <figure xml:id="fig-sd-rule-int-rate">
        <caption>Standard deviations in the interest rate distribution</caption>
        <image source="ch_summarizing_data/figures/sdRuleForIntRate/sdRuleForIntRate.png" width="73%">
          <description>
            A dot plot of 50 observations is shown with values ranging from about 5% to 26%. The data set is the
            same as that shown in earlier dot plots, where the data is more dense from 5% to about 11%, has medium
            density from about 12% to 20%, and then there are a few more values scattered in the 20% to 27% range.
            Shading is shown to represent the regions within 1, 2, and 3 standard deviations. The region within 1
            standard deviation is from 6.5% to 16.7%, representing 34 of the 50 data points. The region within 2
            standard deviations runs left off of the chart (but would be from about 1.4%) to 21.8% and contains 48
            of the 50 data points. The third standard deviation is shown to extend out to 26.9%, and all 50
            observations are contained within the 3 standard deviations.
          </description>
        </image>
      </figure>

      <p>
        For the <c>interest_rate</c> variable, 34 of the 50 loans (68%) had interest rates within 1 standard
        deviation of the mean, and 48 of the 50 loans (96%) had rates within 2 standard deviations. Usually about
        70% of the data are within 1 standard deviation of the mean and 95% within 2 standard deviations, though
        this is far from a hard rule.
      </p>

      <figure xml:id="fig-different-dists-same-sd">
        <caption>Three very different population distributions with the same mean <m>\mu=0</m> and standard deviation <m>\sigma=1</m></caption>
        <image source="ch_summarizing_data/figures/severalDiffDistWithSdOf1/severalDiffDistWithSdOf1.png" width="60%">
          <description>
            Three histograms are shown (upper, middle, lower). Each distribution also shows shading -- dark gray
            between -1 to 1, lighter gray between -2 and 2, and light gray between -3 and 3, and then very light
            gray further out. The upper plot shows only two bins with non-zero values and of equal height at -1 and
            1. The middle plot shows a bell-shaped curve, where most of the higher bin values are between -1 and 1,
            middling heights are between -2 to -1 and 1 to 2, and the data trails off in each direction with
            ever-smaller values further out. The lower histogram shows no data below about -1.6, a quick increase to
            a peak at about -0.7 and then a slow decline of values to about half the max height at 1 and further
            trails off to ever smaller values to a horizontal location of 3 and beyond.
          </description>
        </image>
      </figure>

      <exercise xml:id="ex-shape-importance">
        <title>Importance of shape description</title>
        <statement>
          <p>
            The concept of shape of a distribution was introduced earlier. A good description of the shape of a
            distribution should include modality and whether the distribution is symmetric or skewed to one side.
            Using <xref ref="fig-different-dists-same-sd"/> as an example, explain why such a description is important.
          </p>
        </statement>
        <solution>
          <p>
            <xref ref="fig-different-dists-same-sd"/> shows three distributions that look quite different, but all
            have the same mean, variance, and standard deviation. Using modality, we can distinguish between the first
            plot (bimodal) and the last two (unimodal). Using skewness, we can distinguish between the last plot (right
            skewed) and the first two. While a picture, like a histogram, tells a more complete story, we can use
            modality and shape (symmetry/skew) to characterize basic information about a distribution.
          </p>
        </solution>
      </exercise>

      <example xml:id="ex-describe-interest-distribution">
        <title>Describing a distribution</title>
        <statement>
          <p>
            Describe the distribution of the <c>interest_rate</c> variable using the histogram in
            <xref ref="fig-loan50-int-rate-hist"/>. The description should incorporate the center, variability, and
            shape of the distribution, and it should also be placed in context. Also note any especially unusual cases.
          </p>
        </statement>
        <solution>
          <p>
            The distribution of interest rates is unimodal and skewed to the high end. Many of the rates fall near
            the mean at 11.57%, and most fall within one standard deviation (5.05%) of the mean. There are a few
            exceptionally large interest rates in the sample that are above 20%.
          </p>
        </solution>
      </example>

      <p>
        In practice, the variance and standard deviation are sometimes used as a means to an end, where the "end"
        is being able to accurately estimate the uncertainty associated with a sample statistic. For example, in
        later chapters the standard deviation is used in calculations that help us understand how much a sample
        mean varies from one sample to the next.
      </p>
    </subsection>

    <!-- Subsection 2.1.5: Box plots, quartiles, and the median -->
    <subsection xml:id="subsec-boxplots-quartiles">
      <title>Box plots, quartiles, and the median</title>

      <p>
        A <term>box plot</term> summarizes a data set using five statistics while also plotting unusual
        observations. <xref ref="fig-loan-int-rate-boxplot"/> provides a vertical dot plot alongside a box plot
        of the <c>interest_rate</c> variable from the <c>loan50</c> data set.
      </p>

      <figure xml:id="fig-loan-int-rate-boxplot">
        <caption>A vertical dot plot next to a labeled box plot for the interest rates of the 50 loans</caption>
        <image source="ch_summarizing_data/figures/loan_int_rate_box_plot_layout/loan_int_rate_box_plot_layout.png" width="86%">
          <description>
            What is shown is a dot plot adjacent to what is called a "box plot". The data values are the same ones
            used in past dot plots, where the data shows greatest density from 5% to 11%, moderate density from 12%
            to 20%, and then a few more values at about 22%, 25%, and 26%. The box plot adjacent to the data shows
            a box that would encapsulate the middle 50% of the data, from about 8% to 13%. The median is also
            annotated with a line through the center of the box. From here, the data extend out with "whiskers" up
            to a distance up to 1.5 times IQR below and above the box to capture as much data as possible. There are
            two observations that extend beyond this range at 25% and 26%.
          </description>
        </image>
      </figure>

      <p>
        The first step in building a box plot is drawing a dark line denoting the <term>median</term>, which
        splits the data in half. <xref ref="fig-loan-int-rate-boxplot"/> shows 50% of the data falling below
        the median and other 50% falling above the median. There are 50 loans in the data set (an even number)
        so the data are perfectly split into two groups of 25. We take the median in this case to be the average
        of the two observations closest to the 50<m>^{th}</m> percentile, which happen to be the same value in
        this data set: <m>(9.93\% + 9.93\%) / 2 = 9.93\%</m>. When there are an odd number of observations,
        there will be exactly one observation that splits the data into two halves, and in such a case that
        observation is the median (no average needed).
      </p>

      <assemblage xml:id="def-median">
        <title>Median: the number in the middle</title>
        <p>
          If the data are ordered from smallest to largest, the <term>median</term> is the observation right in
          the middle. If there are an even number of observations, there will be two values in the middle, and
          the median is taken as their average.
        </p>
      </assemblage>

      <p>
        The second step in building a box plot is drawing a rectangle to represent the middle 50% of the data.
        The total length of the box, shown vertically in <xref ref="fig-loan-int-rate-boxplot"/>, is called the
        <term>interquartile range</term> (<term>IQR</term>, for short). It, like the standard deviation, is a
        measure of variability in data. The more variable the data, the larger the standard deviation and IQR
        tend to be. The two boundaries of the box are called the <term>first quartile</term> (the 25<m>^{th}</m>
        percentile, i.e. 25% of the data fall below this value) and the <term>third quartile</term> (the
        75<m>^{th}</m> percentile), and these are often labeled <m>Q_1</m> and <m>Q_3</m>, respectively.
      </p>

      <assemblage xml:id="def-iqr">
        <title>Interquartile range (IQR)</title>
        <p>
          The IQR is the length of the box in a box plot. It is computed as
          <md>
            <mrow>IQR = Q_3 - Q_1</mrow>
          </md>
          where <m>Q_1</m> and <m>Q_3</m> are the 25<m>^{th}</m> and 75<m>^{th}</m> percentiles.
        </p>
      </assemblage>

      <exercise xml:id="ex-quartile-percentages">
        <title>Data between quartiles</title>
        <statement>
          <p>
            What percent of the data fall between <m>Q_1</m> and the median? What percent is between the median
            and <m>Q_3</m>?
          </p>
        </statement>
        <solution>
          <p>
            Since <m>Q_1</m> and <m>Q_3</m> capture the middle 50% of the data and the median splits the data in
            the middle, 25% of the data fall between <m>Q_1</m> and the median, and another 25% falls between the
            median and <m>Q_3</m>.
          </p>
        </solution>
      </exercise>

      <p>
        Extending out from the box, the <term>whiskers</term> attempt to capture the data outside of the box.
        However, their reach is never allowed to be more than <m>1.5 \times IQR</m>. They capture everything
        within this reach. In <xref ref="fig-loan-int-rate-boxplot"/>, the upper whisker does not extend to the
        last two points, which is beyond <m>Q_3 + 1.5 \times IQR</m>, and so it extends only to the last point
        below this limit. The lower whisker stops at the lowest value, 5.31%, since there is no additional data
        to reach; the lower whisker's limit is not shown in the figure because the plot does not extend down to
        <m>Q_1 - 1.5 \times IQR</m>. In a sense, the box is like the body of the box plot and the whiskers are
        like its arms trying to reach the rest of the data.
      </p>

      <p>
        Any observation lying beyond the whiskers is labeled with a dot. The purpose of labeling these points
        <mdash/> instead of extending the whiskers to the minimum and maximum observed values <mdash/> is to
        help identify any observations that appear to be unusually distant from the rest of the data. Unusually
        distant observations are called <term>outliers</term>. In this case, it would be reasonable to classify
        the interest rates of 24.85% and 26.30% as outliers since they are numerically distant from most of the
        data.
      </p>

      <assemblage xml:id="def-outliers">
        <title>Outliers are extreme</title>
        <p>
          An <term>outlier</term> is an observation that appears extreme relative to the rest of the data.
        </p>
        <p>
          Examining data for outliers serves many useful purposes, including:
          <ol>
            <li><p>Identifying strong skew in the distribution.</p></li>
            <li><p>Identifying possible data collection or data entry errors.</p></li>
            <li><p>Providing insight into interesting properties of the data.</p></li>
          </ol>
        </p>
      </assemblage>

      <exercise xml:id="ex-estimate-quartiles">
        <title>Estimating quartiles from a box plot</title>
        <statement>
          <p>
            Using <xref ref="fig-loan-int-rate-boxplot"/>, estimate the following values for <c>interest_rate</c>
            in the <c>loan50</c> data set:
            (a) <m>Q_1</m>, (b) <m>Q_3</m>, and (c) IQR.
          </p>
        </statement>
        <solution>
          <p>
            These visual estimates will vary a little from one person to the next: <m>Q_1 \approx</m> 8%,
            <m>Q_3 \approx</m> 14%, <m>IQR = Q_3 - Q_1 \approx</m> 6%. (The true values: <m>Q_1 = 7.96\%</m>,
            <m>Q_3 = 13.72\%</m>, <m>IQR = 5.76\%</m>.)
          </p>
        </solution>
      </exercise>
    </subsection>

    <!-- Subsection 2.1.6: Robust statistics -->
    <subsection xml:id="subsec-robust-stats">
      <title>Robust statistics</title>

      <p>
        How are the sample statistics of the <c>interest_rate</c> data set affected by the observation, 26.3%?
        What would have happened if this loan had instead been only 15%? What would happen to these summary
        statistics if the observation at 26.3% had been even larger, say 35%? These scenarios are plotted
        alongside the original data in <xref ref="fig-loan-int-rate-robust"/>, and sample statistics are computed
        under each scenario in <xref ref="table-robust-comparison"/>.
      </p>

      <figure xml:id="fig-loan-int-rate-robust">
        <caption>Dot plots of the original interest rate data and two modified data sets</caption>
        <image source="ch_summarizing_data/figures/loan_int_rate_robust_ex/loan_int_rate_robust_ex.png" width="100%">
          <description>
            Three dot plots are shown in the same plot. The largest observation from the original data set
            (discussed in previous dot plots) at about 26% is moved to 15% in the second dot plot and instead
            to 35% in the third dot plot.
          </description>
        </image>
      </figure>

      <table xml:id="table-robust-comparison">
        <title>Comparison of statistics under different scenarios</title>
        <tabular>
          <row header="yes" bottom="medium">
            <cell>Scenario</cell>
            <cell colspan="2" halign="center">Robust</cell>
            <cell colspan="2" halign="center">Not Robust</cell>
          </row>
          <row header="yes" bottom="minor">
            <cell></cell>
            <cell>Median</cell>
            <cell>IQR</cell>
            <cell><m>\bar{x}</m></cell>
            <cell><m>s</m></cell>
          </row>
          <row>
            <cell>Original <c>interest_rate</c> data</cell>
            <cell>9.93%</cell>
            <cell>5.76%</cell>
            <cell>11.57%</cell>
            <cell>5.05%</cell>
          </row>
          <row>
            <cell>Move 26.3% <m>\to</m> 15%</cell>
            <cell>9.93%</cell>
            <cell>5.76%</cell>
            <cell>11.34%</cell>
            <cell>4.61%</cell>
          </row>
          <row>
            <cell>Move 26.3% <m>\to</m> 35%</cell>
            <cell>9.93%</cell>
            <cell>5.76%</cell>
            <cell>11.74%</cell>
            <cell>5.68%</cell>
          </row>
        </tabular>
      </table>

      <exercise xml:id="ex-robustness-comparison">
        <title>Comparing robustness of statistics</title>
        <statement>
          <p>
            (a) Which is more affected by extreme observations, the mean or median? <xref ref="table-robust-comparison"/>
            may be helpful. (b) Is the standard deviation or IQR more affected by extreme observations?
          </p>
        </statement>
        <solution>
          <p>
            (a) Mean is affected more. (b) Standard deviation is affected more. Complete explanations are provided
            below.
          </p>
        </solution>
      </exercise>

      <p>
        The median and IQR are called <term>robust statistics</term> because extreme observations have little
        effect on their values: moving the most extreme value generally has little influence on these statistics.
        On the other hand, the mean and standard deviation are more heavily influenced by changes in extreme
        observations, which can be important in some situations.
      </p>

      <example xml:id="ex-why-robust-stable">
        <title>Stability of robust statistics</title>
        <statement>
          <p>
            The median and IQR did not change under the three scenarios in <xref ref="table-robust-comparison"/>.
            Why might this be the case?
          </p>
        </statement>
        <solution>
          <p>
            The median and IQR are only sensitive to numbers near <m>Q_1</m>, the median, and <m>Q_3</m>. Since
            values in these regions are stable in the three data sets, the median and IQR estimates are also stable.
          </p>
        </solution>
      </example>

      <exercise xml:id="ex-mean-vs-median-choice">
        <title>Choosing between mean and median</title>
        <statement>
          <p>
            The distribution of loan amounts in the <c>loan50</c> data set is right skewed, with a few large loans
            lingering out into the right tail. If you were wanting to understand the typical loan size, should you
            be more interested in the mean or median?
          </p>
        </statement>
        <solution>
          <p>
            Answers will vary! If we're looking to simply understand what a typical individual loan looks like, the
            median is probably more useful. However, if the goal is to understand something that scales well, such
            as the total amount of money we might need to have on hand if we were to offer 1,000 loans, then the
            mean would be more useful.
          </p>
        </solution>
      </exercise>
    </subsection>

    <!-- Subsection 2.1.7: Transforming data (special topic) -->
    <subsection xml:id="subsec-transforming-data">
      <title>Transforming data (special topic)</title>

      <p>
        When data are very strongly skewed, we sometimes transform them so they are easier to model.
      </p>

      <figure xml:id="fig-county-pop-transformed">
        <caption>County population distributions: (a) original data showing extreme skew, (b) log-transformed data</caption>
        <image source="ch_summarizing_data/figures/county_pop_transformed/county_pop_transformed.png" width="90%">
          <description>
            Two histograms are shown side by side. The first histogram has a horizontal axis of Population with
            possible data ranging from 0 to about 10 million. The first bar representing 0 to 400,000 shows a
            frequency (bar height) of about 3000, the second bar for 400,000 to 800,000 shows about frequency of
            about 100. All other bars are sufficiently small that they are virtually indistinguishable from 0. The
            second histogram shows the horizontal axis represents log-base-10 of the population. The horizontal axis
            runs from about 2 to 7, and frequency (bin/box height) peaks at a little over 1000. The data show an
            approximate bell shape, peaking in the middle between 4 to 4.5, then showing lower frequencies the
            further out from 4-4.5 with frequencies being close to zero outside of 2.5 to 6.5.
          </description>
        </image>
      </figure>

      <example xml:id="ex-extreme-skew-problem">
        <title>Issues with extreme skew</title>
        <statement>
          <p>
            Consider the histogram of county populations shown in <xref ref="fig-county-pop-transformed"/> (left
            panel), which shows extreme skew. What isn't useful about this plot?
          </p>
        </statement>
        <solution>
          <p>
            Nearly all of the data fall into the left-most bin, and the extreme skew obscures many of the
            potentially interesting details in the data.
          </p>
        </solution>
      </example>

      <p>
        There are some standard transformations that may be useful for strongly right skewed data where much of
        the data is positive but clustered near zero. A <term>transformation</term> is a rescaling of the data
        using a function. For instance, a plot of the logarithm (base 10) of county populations results in the
        new histogram in <xref ref="fig-county-pop-transformed"/> (right panel). This data is symmetric, and any
        potential outliers appear much less extreme than in the original data set. By reigning in the outliers
        and extreme skew, transformations like this often make it easier to build statistical models against the
        data.
      </p>

      <p>
        Transformations can also be applied to one or both variables in a scatterplot. A scatterplot of the
        population change from 2010 to 2017 against the population in 2010 is shown in
        <xref ref="fig-pop-change-transform"/>. In the first scatterplot, it's hard to decipher any interesting
        patterns because the population variable is so strongly skewed. However, if we apply a log<m>_{10}</m>
        transformation to the population variable, as shown in the second panel, a positive association between
        the variables is revealed.
      </p>

      <figure xml:id="fig-pop-change-transform">
        <caption>Scatterplots of population change vs. population: (a) original data, (b) log-transformed population</caption>
        <image source="ch_summarizing_data/figures/county_pop_change_v_pop_transform/county_pop_change_v_pop_transform.png" width="90%">
          <description>
            Two scatterplots are shown side by side. The first scatterplot has population on the horizontal axis
            (ranging from 0 to 10 million) and population change as a percent on the vertical axis (ranging from
            -35% to positive 40%). The data is particularly concentrated on the left of the graph below 1 million.
            There is no discernible trend in the data. The second scatterplot has log-base-10 of the population on
            the horizontal axis (ranging from 2 to 7) and population change as a percent on the vertical axis. The
            data is well distributed and shows a cloud of points with a slight upward trend.
          </description>
        </image>
      </figure>

      <p>
        Transformations other than the logarithm can be useful, too. For instance, the square root and inverse are
        commonly used by data scientists. Common goals in transforming data are to see the data structure
        differently, reduce skew, assist in modeling, or straighten a nonlinear relationship in a scatterplot.
      </p>
    </subsection>

    <!-- Subsection 2.1.8: Mapping data (special topic) -->
    <subsection xml:id="subsec-mapping-data">
      <title>Mapping data (special topic)</title>

      <p>
        The <c>county</c> data set offers many numerical variables that we could plot using dot plots,
        scatterplots, or box plots, but these miss the true nature of the data. Rather, when we encounter
        geographic data, we should create an <term>intensity map</term>, where colors are used to show higher and
        lower values of a variable. Figures throughout this book demonstrate a variety of intensity maps for
        county-level data including median household income, poverty rate, homeownership rate, federal spending per
        capita, and unemployment rate.
      </p>

      <p>
        The maps are not generally very helpful for getting precise values, but they are very helpful for seeing
        spatial patterns and can help us generate interesting research questions.
      </p>
    </subsection>

    <!-- End of Section 2.1 subsections -->

  </section>

  <!-- Section 2.2: Considering categorical data -->
  <section xml:id="sec-categorical-data">
    <title>Considering categorical data</title>
    <p>
      <em>Content for Section 2.2 will be added, following the same pattern as Section 2.1.</em>
    </p>
  </section>

  <!-- Section 2.3: Case study malaria vaccine (existing content from current file) -->

</chapter>
